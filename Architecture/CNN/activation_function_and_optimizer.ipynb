{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "normal cnn ",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE6ZmMrNTwcs"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import all the requirements \n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "jFhslnUoVNBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/data/skin_cancer /skincancer.zip\" \"/content/\""
      ],
      "metadata": {
        "id": "i_nNFvPMVWIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/skincancer.zip\""
      ],
      "metadata": {
        "id": "4KdoMdfzVlhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-3\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 300\n",
        "IMAGE_SIZE = 256\n",
        "default_image_size = tuple((IMAGE_SIZE, IMAGE_SIZE))\n",
        "image_size = 0\n",
        "data_dir = \"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\n",
        "CHANNELS=3\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "3HdH8uhvVOW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    \n",
        "    ds_size = ds.cardinality().numpy()\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "yBWKRiUPVtdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  seed=123,\n",
        "  image_size=default_image_size,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "\n",
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "mMbbNyLpVxI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.class_names\n",
        "n_classes = len(class_names)\n",
        "print(n_classes, class_names)"
      ],
      "metadata": {
        "id": "2NVcZj0jVz8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the sample images from the dataset\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "Pv1NivSeV2Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "xQA8l32CWT42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "ICnKixHRWY0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "])"
      ],
      "metadata": {
        "id": "RXa8wdOKWcSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "y04ba7QHWfQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "batch_input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    input_shape = (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "    batch_input_shape = (BATCH_SIZE, CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
        "    chanDim = 1"
      ],
      "metadata": {
        "id": "_FfWKOijWjL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.build(input_shape=batch_input_shape)"
      ],
      "metadata": {
        "id": "V1lebKf9WkO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "HgbwZuoAWrWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the Model\n",
        "model.compile(\n",
        "    optimizer='Adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "LvNlu97QWuPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer ==\"Adam\" Adam with relu\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "metadata": {
        "id": "s5H15_KaW0GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer = \"Adam\"   Adam with relu\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tdjpQUTvXNZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "model.save(\"CNN300.h5\")"
      ],
      "metadata": {
        "id": "UhLNiTe_Xj2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer ==\"SGD\" SGD with Sigmoid \n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "metadata": {
        "id": "4lZBArh3YRSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer = \"Sigmoid\"  SGD with Sigmoid \n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o4cuzRwAYZ38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer ==\"Adam\" Adam with Sigmoid\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "metadata": {
        "id": "hs5GBORUZQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer = \"Sigmoid\"  SGD with Sigmoid \n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nxNtC_TvZdNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer ==\"Adam\" SGD with relu\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ],
      "metadata": {
        "id": "wkkvWPraa57D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizer = \"Sigmoid\"  SGD with relu \n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xeSuimHPa_7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}